import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pickle
import re
import os
import joblib
from datetime import datetime
from sklearn.ensemble import IsolationForest
from difflib import SequenceMatcher
from math import ceil

st.set_page_config(layout="wide")

st.markdown("""
<style>
    .main {
        padding-right: 0rem !important;
        padding-left: 0rem !important;
    }
    .block-container {
        padding-left: 1rem;
        padding-right: 1rem;
        max-width: 100% !important;
    }
</style>
""", unsafe_allow_html=True)




menu = ["Gi·ªõi thi·ªáu", "X√¢y d·ª±ng m√¥ h√¨nh", "D·ª± ƒëo√°n gi√° xe","Danh s√°ch xe gi√° b·∫•t th∆∞·ªùng"]
choice = st.sidebar.selectbox('Menu', menu)    
if choice == 'Gi·ªõi thi·ªáu':
    st.markdown("### **·ª®NG D·ª§NG D·ª∞ ƒêO√ÅN GI√Å XE M√ÅY C≈® V√Ä PH√ÅT HI·ªÜN GI√Å B·∫§T TH∆Ø·ªúNG**")
    st.image("xe_may_cu.jpg") 
    # --- PH·∫¶N 1: D·ª∞ ƒêO√ÅN GI√Å XE ---
    st.markdown("### **D·ª∞ ƒêO√ÅN GI√Å XE**")
    st.markdown('<div class="bullet">‚Ä¢ ·ª®ng d·ª•ng cung c·∫•p c√¥ng c·ª• h·ªó tr·ª£ ƒë·ªãnh gi√° v√† g·ª£i √Ω, gi√∫p minh b·∫°ch ho√° th·ªã tr∆∞·ªùng xe m√°y c≈© v√† tƒÉng t·ªâ l·ªá giao d·ªãch th√†nh c√¥ng.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ H·ªó tr·ª£ ng∆∞·ªùi b√°n ƒë·ªãnh gi√° h·ª£p l√Ω cho xe m√°y c≈© d·ª±a tr√™n c√°c ƒë·∫∑c ƒëi·ªÉm nh∆∞ th∆∞∆°ng hi·ªáu, nƒÉm s·∫£n xu·∫•t, t√¨nh tr·∫°ng v√† khu v·ª±c.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ Gi√∫p ng∆∞·ªùi mua so s√°nh v√† nh·∫≠n di·ªán m·ª©c gi√° h·ª£p l√Ω, tr√°nh b·ªã ƒë·ªãnh gi√° qu√° cao.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ T·ªëi ∆∞u h√≥a doanh thu v√† tr·∫£i nghi·ªám ng∆∞·ªùi d√πng cho Ch·ª£ T·ªët th√¥ng qua vi·ªác g·ª£i √Ω m·ª©c gi√° ph√π h·ª£p, tƒÉng kh·∫£ nƒÉng giao d·ªãch th√†nh c√¥ng.</div>', unsafe_allow_html=True)

    # --- KHO·∫¢NG C√ÅCH GI·ªÆA HAI PH·∫¶N ---
    st.markdown("<br><br>", unsafe_allow_html=True)

    # --- PH·∫¶N 2: DANH S√ÅCH XE GI√Å B·∫§T TH∆Ø·ªúNG ---
    st.markdown("### **DANH S√ÅCH XE GI√Å B·∫§T TH∆Ø·ªúNG**")
    st.markdown('<div class="bullet">‚Ä¢ Gi√∫p h·ªá th·ªëng nhanh ch√≥ng ph√°t hi·ªán nh·ªØng tin ƒëƒÉng c√≥ m·ª©c gi√° ch√™nh l·ªách ƒë√°ng k·ªÉ so v·ªõi m·∫∑t b·∫±ng chung c·ªßa th·ªã tr∆∞·ªùng.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ H·ªó tr·ª£ s√†n giao d·ªãch nh·∫≠n di·ªán c√°c tr∆∞·ªùng h·ª£p ƒë·ªãnh gi√° qu√° th·∫•p (nguy c∆° l·ª´a ƒë·∫£o) ho·∫∑c qu√° cao (ƒë·∫∑t gi√° sai l·ªách).</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ Cho ph√©p ƒë·ªôi ki·ªÉm duy·ªát t·∫≠p trung ki·ªÉm tra c√°c tin ƒëƒÉng ƒë√°ng nghi tr∆∞·ªõc, ti·∫øt ki·ªám th·ªùi gian v√† n√¢ng cao hi·ªáu qu·∫£ x·ª≠ l√Ω.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ G√≥p ph·∫ßn ƒë·∫£m b·∫£o t√≠nh minh b·∫°ch, gi√∫p ng∆∞·ªùi mua y√™n t√¢m h∆°n khi l·ª±a ch·ªçn xe v√† h·∫°n ch·∫ø c√°c tin g√¢y nhi·ªÖu tr√™n s√†n.</div>', unsafe_allow_html=True)
    st.markdown('<div class="bullet">‚Ä¢ B·∫£o v·ªá ng∆∞·ªùi b√°n uy t√≠n kh·ªèi vi·ªác b·ªã c·∫°nh tranh kh√¥ng l√†nh m·∫°nh b·ªüi c√°c tin ƒëƒÉng ƒë·∫∑t gi√° b·∫•t h·ª£p l√Ω.</div>', unsafe_allow_html=True)   
    # --- KHO·∫¢NG C√ÅCH GI·ªÆA HAI PH·∫¶N ---
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # TH√ÄNH VI√äN ---
    st.markdown("### **TH√ÄNH VI√äN**")
    # d·ªØ li·ªáu
    data = {
        "STT": [1, 2, 3],
        "H·ªç t√™n": ["Mai B·∫£o Ng·ªçc", "B√πi Ng·ªçc To·∫£n", "Nguy·ªÖn V≈© Duy"],
        "Vai tr√≤": ["X√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o gi√°", "X√¢y d·ª±ng m√¥ h√¨nh ph√°t hi·ªán b·∫•t th∆∞·ªùng", "L·∫≠p danh s√°ch xe gi√° b·∫•t th∆∞·ªùng"]
    }
    df = pd.DataFrame(data)

    # hi·ªÉn th·ªã
    st.table(df.set_index("STT"))  
    
elif choice == 'X√¢y d·ª±ng m√¥ h√¨nh':
    st.markdown("### **1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**")

    st.markdown("""
    B·ªô d·ªØ li·ªáu xe m√°y c≈© ƒë∆∞·ª£c thu th·∫≠p t·ª´ n·ªÅn t·∫£ng *Ch·ª£ T·ªët*, bao g·ªìm c√°c thu·ªôc t√≠nh ph·∫£n √°nh ƒë·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t, m·ª©c ƒë·ªô s·ª≠ d·ª•ng v√† gi√° rao b√°n c·ªßa xe. 
    Tr∆∞·ªõc khi ƒë∆∞a v√†o m√¥ h√¨nh d·ª± b√°o, d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω v√† chu·∫©n h√≥a theo quy tr√¨nh sau:
    """)

    st.markdown("""
    <ul style="line-height: 1.8;">
    <li>Chu·∫©n h√≥a c√°c tr∆∞·ªùng gi√° (<i>Gi√°</i>, <i>Kho·∫£ng gi√° min</i>, <i>Kho·∫£ng gi√° max</i>) nh·∫±m ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n khi ph√¢n t√≠ch.</li>
    <li>Lo·∫°i b·ªè c√°c b·∫£n ghi thi·∫øu d·ªØ li·ªáu quan tr·ªçng ho·∫∑c ch·ª©a gi√° tr·ªã ngo·∫°i lai g√¢y ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng m√¥ h√¨nh.</li>
    <li>Chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu cho c√°c bi·∫øn s·ªë nh∆∞ <i>NƒÉm ƒëƒÉng k√Ω</i>, <i>S·ªë Km ƒë√£ ƒëi</i>, ‚Ä¶ ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch v·ªõi c√°c thu·∫≠t to√°n h·ªçc m√°y.</li>
    <li>Th·ª±c hi·ªán scaling cho c√°c bi·∫øn li√™n t·ª•c nh·∫±m gi·∫£m sai l·ªách thang ƒëo v√† c·∫£i thi·ªán ƒë·ªô ·ªïn ƒë·ªãnh trong qu√° tr√¨nh hu·∫•n luy·ªán.</li>
    </ul>
    """, unsafe_allow_html=True)

    st.markdown(""" 
    C√°c bi·∫øn ph√¢n lo·∫°i (<i>Th∆∞∆°ng hi·ªáu</i>, <i>D√≤ng xe</i>, <i>...</i>) ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng <b>StringIndexer</b> v√† <b>OneHotEncoder</b>. 
    Sau ƒë√≥ to√†n b·ªô ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c h·ª£p nh·∫•t th√†nh m·ªôt vector ƒë·∫ßu v√†o duy nh·∫•t th√¥ng qua <b>VectorAssembler</b>.
    """, unsafe_allow_html=True)

    st.markdown("""
    D·ªØ li·ªáu sau khi chu·∫©n h√≥a ƒë∆∞·ª£c chia theo t·ª∑ l·ªá:
    """)

    st.markdown("""
    <ul style="line-height: 1.8;">
    <li><b>80%</b> d√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.</li>
    <li><b>20%</b> d√πng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t d·ª± b√°o.</li>
    </ul>
    """, unsafe_allow_html=True)




# --- X√ÇY D·ª∞NG M√î H√åNH D·ª∞ B√ÅO GI√Å ---

    st.markdown("### **2. X√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o gi√°**")

    st.markdown("""
    Nh√≥m ti·∫øn h√†nh hu·∫•n luy·ªán nhi·ªÅu thu·∫≠t to√°n kh√°c nhau nh·∫±m so s√°nh hi·ªáu nƒÉng v√† l·ª±a ch·ªçn m√¥ h√¨nh t·ªëi ∆∞u, bao g·ªìm:
    """)

    # Bullet list c√°c thu·∫≠t to√°n
    st.markdown("""
    <ul style="line-height: 1.8;">
    <li>Linear Regression</li>
    <li>Random Forest Regressor</li>
    <li>Gradient Boosted Trees (GBT)</li>
    </ul>
    """, unsafe_allow_html=True)

    st.markdown("""
    T·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë·ªÅu ƒë∆∞·ª£c ƒë√°nh gi√° b·∫±ng c√πng m·ªôt b·ªô th∆∞·ªõc ƒëo:
    """)

    # Bullet list c√°c ch·ªâ s·ªë ƒë√°nh gi√°
    st.markdown("""
    <ul style="line-height: 1.8;">
    <li><b>MAE (Mean Absolute Error)</b>: sai s·ªë d·ª± b√°o trung b√¨nh tuy·ªát ƒë·ªëi gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† gi√° tr·ªã d·ª± ƒëo√°n.</li>
    <li><b>R¬≤ (h·ªá s·ªë x√°c ƒë·ªãnh)</b>: ƒë·ªô ph√π h·ª£p c·ªßa m√¥ h√¨nh (c√†ng cao c√†ng t·ªët).</li>
    </ul>
    """, unsafe_allow_html=True)

    st.markdown("K·∫øt qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh:")

    # --- B·∫¢NG K·∫æT QU·∫¢ ---
    import pandas as pd

    results = {
        "M√¥ h√¨nh": [
            "Linear Regression",
            "Random Forest",
            "Gradient Boosted Trees (GBT)"
        ],
        "MAE (VND)": [
            "6.700.876.000",
            "5.744.014",
            "7.142.370",
        ],
        "R¬≤": [
            "-5,98e+19",
            "0,7518",
            "0,6962",
        ],
        "Nh·∫≠n x√©t": [
            "Sai s·ªë c·ª±c l·ªõn v√† R¬≤ √¢m n√™n m√¥ h√¨nh ho√†n to√†n kh√¥ng ph√π h·ª£p v·ªõi d·ªØ li·ªáu",
            "Sai s·ªë th·∫•p nh·∫•t v√† R¬≤ cao nh·∫•t, l√† m√¥ h√¨nh cho hi·ªáu su·∫•t t·ªët nh·∫•t",
            "Sai s·ªë v√† R¬≤ ·ªü m·ª©c kh√°, nh∆∞ng v·∫´n k√©m h∆°n Random Forest",
        ]
    }

    df_result = pd.DataFrame(results)

    # ·∫®n index
    st.dataframe(df_result, hide_index=True)
    
    st.markdown("""
    K·∫øt qu·∫£ so s√°nh m√¥ h√¨nh cho th·∫•y Random Forest ho·∫°t ƒë·ªông t·ªët nh·∫•t trong ba m√¥ h√¨nh, v·ªõi gi√° tr·ªã MAE ‚âà 5.74 v√† R¬≤ ‚âà 0.75, cho th·∫•y m√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c kho·∫£ng 75% ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu gi√° xe v√† c√≥ sai s·ªë d·ª± ƒëo√°n trung b√¨nh th·∫•p nh·∫•t. M√¥ h√¨nh Gradient Boosting ƒë·ª©ng th·ª© hai, c√≥ ƒë·ªô ch√≠nh x√°c kh√° t·ªët nh∆∞ng k√©m h∆°n m·ªôt ch√∫t so v·ªõi Random Forest (MAE ‚âà 7.14, R¬≤ ‚âà 0.70). Ng∆∞·ª£c l·∫°i, Linear Regression cho k·∫øt qu·∫£ r·∫•t k√©m, v·ªõi MAE c·ª±c l·ªõn, R¬≤ √¢m (‚âà ‚Äì5.98e+19), ch·ª©ng t·ªè m√¥ h√¨nh tuy·∫øn t√≠nh kh√¥ng ph√π h·ª£p v·ªõi t·∫≠p d·ªØ li·ªáu n√†y ‚Äì c√≥ th·ªÉ do m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn ƒë·ªôc l·∫≠p v√† gi√° xe l√† phi tuy·∫øn t√≠nh v√† ph·ª©c t·∫°p. Nh∆∞ v·∫≠y, Random Forest l√† l·ª±a ch·ªçn t·ªëi ∆∞u ƒë·ªÉ d·ª± ƒëo√°n gi√° xe m√°y trong tr∆∞·ªùng h·ª£p n√†y.
    """)
    
    # Hi·ªÉn th·ªã m√¥ t·∫£ quy tr√¨nh ph√°t hi·ªán gi√° b·∫•t th∆∞·ªùng (ch·ªâ hi·ªÉn th·ªã vƒÉn b·∫£n)
    st.markdown("### **3. Quy tr√¨nh ph√°t hi·ªán gi√° b·∫•t th∆∞·ªùng**")

    st.markdown("""
    **B∆∞·ªõc 1 ‚Äî T√≠nh sai s·ªë d·ª± b√°o (Residual)**  
    `residual = gi√° th·ª±c ‚àí gi√° d·ª± ƒëo√°n` ‚Äî cho bi·∫øt gi√° ƒëang r·∫ª h∆°n hay ƒë·∫Øt h∆°n so v·ªõi d·ª± ƒëo√°n.

    **B∆∞·ªõc 2 ‚Äî L·∫•y th·ªëng k√™ ph√¢n kh√∫c**  
    H·ªá th·ªëng l·∫•y mean/std, kho·∫£ng h·ª£p l√Ω (min‚Äìmax) v√† ph√¢n v·ªã (P10‚ÄìP90) theo d√≤ng xe; n·∫øu kh√¥ng c√≥, d√πng th·ªëng k√™ to√†n b·ªô.

    **B∆∞·ªõc 3 ‚Äî Chu·∫©n ho√° (Residual-z)**  
    T√≠nh `residual_z = (residual ‚àí mean) / std` ƒë·ªÉ ƒë√°nh gi√° m·ª©c l·ªách theo chu·∫©n.

    **B∆∞·ªõc 4 ‚Äî Ki·ªÉm tra vi ph·∫°m**  
    - Ki·ªÉm tra **min‚Äìmax** (ngo√†i kho·∫£ng h·ª£p l√Ω)  
    - Ki·ªÉm tra **P10‚ÄìP90** (ngo√†i v√πng ph·ªï bi·∫øn)

    **B∆∞·ªõc 5 ‚Äî T√≠nh ƒëi·ªÉm b·∫•t th∆∞·ªùng (0‚Äì100)**  
    K·∫øt h·ª£p 3 t√≠n hi·ªáu v·ªõi tr·ªçng s·ªë: **40% residual-z**, **40% min/max**, **20% P10‚ÄìP90**.

    **B∆∞·ªõc 6 ‚Äî Ph√¢n lo·∫°i**  
    Theo th·ª© t·ª± ∆∞u ti√™n:  
    1. Vi ph·∫°m min/max ‚Üí b·∫•t th∆∞·ªùng (r·∫ª/ƒë·∫Øt)  
    2. Vi ph·∫°m P10‚ÄìP90 ‚Üí b·∫•t th∆∞·ªùng  
    3. `|residual_z| ‚â• 2` ‚Üí b·∫•t th∆∞·ªùng  
    4. `anomaly_score ‚â• 45` ‚Üí b·∫•t th∆∞·ªùng  
    N·∫øu kh√¥ng r∆°i v√†o c√°c tr∆∞·ªùng h·ª£p tr√™n ‚Üí **B√åNH TH∆Ø·ªúNG**.

    **B∆∞·ªõc 7 ‚Äî K·∫øt lu·∫≠n hi·ªÉn th·ªã**  
    Ch·ªâ hi·ªán 1 trong 3 nh√£n cho ng∆∞·ªùi d√πng: **ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG**, **R·∫∫ B·∫§T TH∆Ø·ªúNG**, **B√åNH TH∆Ø·ªúNG**.
    """, unsafe_allow_html=True)


    st.markdown("## **4. L·∫≠p danh s√°ch t·ªïng h·ª£p c√°c xe c√≥ gi√° b·∫•t th∆∞·ªùng**")

    st.markdown("""
    B√™n c·∫°nh vi·ªác ki·ªÉm tra gi√° cho t·ª´ng xe theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h·ªá th·ªëng c√≤n cung c·∫•p ch·ª©c nƒÉng **li·ªát k√™ to√†n b·ªô c√°c tin ƒëƒÉng c√≥ m·ª©c gi√° b·∫•t th∆∞·ªùng** nh·∫±m h·ªó tr·ª£ c√¥ng t√°c ki·ªÉm duy·ªát c·ªßa qu·∫£n tr·ªã vi√™n. 
    M·ª•c ti√™u c·ªßa t√≠nh nƒÉng n√†y l√† gi√∫p admin nhanh ch√≥ng ph√°t hi·ªán nh·ªØng tin rao b√°n l·ªách kh·ªèi m·∫∑t b·∫±ng th·ªã tr∆∞·ªùng v√† ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu tr√™n s√†n giao d·ªãch.
    """)

    st.markdown("### **Quy tr√¨nh x·ª≠ l√Ω c·ªßa admin**")
    st.markdown("""
    - Admin c√≥ th·ªÉ xem chi ti·∫øt t·ª´ng tin ƒëƒÉng, ki·ªÉm tra m√¥ t·∫£ v√† h√¨nh ·∫£nh, sau ƒë√≥ ƒë∆∞a ra quy·∫øt ƒë·ªãnh: ph√™ duy·ªát, x√°c minh l·∫°i ho·∫∑c t·ª´ ch·ªëi.  
    - Danh s√°ch cung c·∫•p n√∫t t·∫£i xu·ªëng CSV ƒë·ªÉ ph·ª•c v·ª• c√¥ng t√°c ki·ªÉm tra h√†ng lo·∫°t v√† l∆∞u tr·ªØ h·ªì s∆° ki·ªÉm duy·ªát.
    """)

    st.markdown("### **L·ª£i √≠ch**")
    st.markdown("""
    <ul style="line-height:1.7;">
    <li>NgƒÉn ch·∫∑n c√°c tin rao c√≥ gi√° qu√° th·∫•p ho·∫∑c qu√° cao m·ªôt c√°ch b·∫•t h·ª£p l√Ω, gi·∫£m nhi·ªÖu th·ªã tr∆∞·ªùng.</li>
    <li>H·ªó tr·ª£ ph√°t hi·ªán s·ªõm c√°c tin c√≥ d·∫•u hi·ªáu gian l·∫≠n ho·∫∑c thi·∫øu minh b·∫°ch.</li>
    <li>B·∫£o v·ªá ng∆∞·ªùi mua b·∫±ng c√°ch c·∫£nh b√°o c√°c m·ª©c gi√° kh√¥ng ph√π h·ª£p.</li>
    <li>Gi√∫p ƒë·ªôi ki·ªÉm duy·ªát l√†m vi·ªác hi·ªáu qu·∫£ h∆°n, duy tr√¨ ch·∫•t l∆∞·ª£ng v√† t√≠nh minh b·∫°ch c·ªßa s√†n giao d·ªãch.</li>
    </ul>
    """, unsafe_allow_html=True)
    





elif choice == 'D·ª± ƒëo√°n gi√° xe':
    import joblib
    import numpy as np
    from datetime import datetime
    st.title("üîç D·ª± ƒëo√°n gi√° xe m√°y & Ph√°t hi·ªán gi√° b·∫•t th∆∞·ªùng")
    st.image("xe_may_cu.jpg", use_container_width=True)

    # -------------------------
    # 1) Load model d·ª± ƒëo√°n
    # -------------------------
    @st.cache_resource(ttl=3600)
    def load_price_model(path="motobike_price_model_project_1.pkl"):
        try:
            return joblib.load(path)
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ load model d·ª± ƒëo√°n t·ª´ {path}: {e}")
            return None

    model = load_price_model("motobike_price_model_project_1.pkl")

    # -------------------------
    # 2) Load d·ªØ li·ªáu m·∫´u & stats ph√¢n kh√∫c
    # -------------------------
    # (N·∫øu b·∫°n ƒë√£ load df ·ªü scope ngo√†i, c√≥ th·ªÉ b·ªè ph·∫ßn n√†y v√† d√πng df c√≥ s·∫µn)
    try:
        df = pd.read_excel("data_motobikes.xlsx")
    except Exception:
        st.error("Kh√¥ng th·ªÉ ƒë·ªçc file data_motobikes.xlsx. Ki·ªÉm tra file ho·∫∑c ƒë∆∞·ªùng d·∫´n.")
        df = pd.DataFrame()
    try:
        stats = pd.read_csv("residual_stats_by_group.csv", index_col=0)
    except Exception:
        st.warning("Kh√¥ng t√¨m th·∫•y residual_stats_by_group.csv; s·ª≠ d·ª•ng th·ªëng k√™ to√†n b·ªô dataset l√†m fallback.")
        stats = None

    # -------------------------
    # 3) Form nh·∫≠p th√¥ng tin xe
    # -------------------------
    st.write("## 1. Nh·∫≠p th√¥ng tin xe ƒë·ªÉ d·ª± ƒëo√°n gi√°")

    # defensive: n·∫øu df r·ªóng th√¨ show input t·ªëi gi·∫£n
    if df.empty:
        thuong_hieu = st.text_input("Ch·ªçn/nh·∫≠p h√£ng xe")
        dong_xe = st.text_input("Ch·ªçn/nh·∫≠p d√≤ng xe")
        tinh_trang = st.text_input("T√¨nh tr·∫°ng")
        loai_xe = st.text_input("Lo·∫°i xe")
        dung_tich = st.text_input("Dung t√≠ch xe (cc)")
        nam_dang_ky = st.number_input("NƒÉm ƒëƒÉng k√Ω", min_value=1900, max_value=datetime.now().year, value=2015)
        tuoi_xe = datetime.now().year - nam_dang_ky
        xuat_xu = st.text_input("Xu·∫•t x·ª©")
        cs_bh = st.text_input("Ch√≠nh s√°ch b·∫£o h√†nh")
        so_km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=200000, value=50000, step=1000)
    else:
        thuong_hieu = st.selectbox("Ch·ªçn h√£ng xe", df['Th∆∞∆°ng hi·ªáu'].unique())
        df_brand = df[df['Th∆∞∆°ng hi·ªáu'] == thuong_hieu]
        dong_xe = st.selectbox("Ch·ªçn d√≤ng xe", df_brand['D√≤ng xe'].unique())
        df_dong = df_brand[df_brand['D√≤ng xe'] == dong_xe]
        tinh_trang = st.selectbox("T√¨nh tr·∫°ng xe", df['T√¨nh tr·∫°ng'].unique())
        loai_xe = st.selectbox("Lo·∫°i xe", df_dong['Lo·∫°i xe'].unique())
        dung_tich = st.selectbox("Dung t√≠ch xe (cc)", df['Dung t√≠ch xe'].unique())
        nam_dang_ky = st.slider("NƒÉm ƒëƒÉng k√Ω", 2000, datetime.now().year, 2015)
        tuoi_xe = datetime.now().year - nam_dang_ky
        xuat_xu = st.selectbox("Xu·∫•t x·ª©", df['Xu·∫•t x·ª©'].unique())
        cs_bh = st.selectbox("Ch√≠nh s√°ch b·∫£o h√†nh", df['Ch√≠nh s√°ch b·∫£o h√†nh'].unique())
        so_km = st.number_input("S·ªë Km ƒë√£ ƒëi", min_value=0, max_value=200000, value=50000, step=1000)

    # n√∫t d·ª± ƒëo√°n
    if st.button("üí° D·ª± ƒëo√°n gi√°"):
        if model is None:
            st.error("Model d·ª± ƒëo√°n ch∆∞a load ƒë∆∞·ª£c. Ki·ªÉm tra file model.")
        else:
            input_data = pd.DataFrame([{
                "Th∆∞∆°ng hi·ªáu": thuong_hieu,
                "D√≤ng xe": dong_xe,
                "T√¨nh tr·∫°ng": tinh_trang,
                "Lo·∫°i xe": loai_xe,
                "Dung t√≠ch xe": dung_tich,
                "NƒÉm ƒëƒÉng k√Ω": nam_dang_ky,
                "Tu·ªïi xe": tuoi_xe,
                "Xu·∫•t x·ª©": xuat_xu,
                "Ch√≠nh s√°ch b·∫£o h√†nh": cs_bh,
                "S·ªë Km ƒë√£ ƒëi": so_km
            }])

            # d·ª± ƒëo√°n (b·∫Øt l·ªói n·∫øu model kh√¥ng ch·∫•p nh·∫≠n input)
            try:
                y_pred = model.predict(input_data)
                # n·∫øu model tr·∫£ v·ªÅ theo "tri·ªáu" th√¨ nh√¢n 1e6
                gia_du_doan_vnd = int(float(y_pred[0]) * 1_000_000)
            except Exception as e:
                st.error(f"Kh√¥ng th·ªÉ d·ª± ƒëo√°n: {e}")
                gia_du_doan_vnd = None

            if gia_du_doan_vnd is not None:
                st.session_state["gia_du_doan_vnd"] = gia_du_doan_vnd
                st.session_state["dong_xe"] = dong_xe
                st.session_state["input_row"] = input_data.iloc[0].to_dict()
                st.success(f"üí∞ Gi√° d·ª± ƒëo√°n: {gia_du_doan_vnd:,.0f} VND")

    # -------------------------
    # 4) Ki·ªÉm tra b·∫•t th∆∞·ªùng  
    # -------------------------
    st.write("## 2. ƒê√°nh gi√° gi√° b·∫•t th∆∞·ªùng")

    gia_thuc = st.number_input("Nh·∫≠p gi√° mu·ªën b√°n (VND)", min_value=0, value=15_000_000, step=100_000)

    if st.button("üìå ƒê√°nh gi√°"):
        if "gia_du_doan_vnd" not in st.session_state:
            st.warning("H√£y b·∫•m 'D·ª± ƒëo√°n gi√°' tr∆∞·ªõc ƒë·ªÉ c√≥ gi√° d·ª± ƒëo√°n.")
        else:
            gia_du_doan_vnd = st.session_state["gia_du_doan_vnd"]
            dong_xe_sel = st.session_state.get("dong_xe", None)

            # -------------------------
            # B∆∞·ªõc 1: residual
            # -------------------------
            resid = gia_thuc - gia_du_doan_vnd

            # -------------------------
            # B∆∞·ªõc 2: l·∫•y th·ªëng k√™ ph√¢n kh√∫c (mean, std, min, max, p10, p90)
            # -------------------------
            if stats is not None and pd.notna(dong_xe_sel) and dong_xe_sel in stats.index:
                seg = stats.loc[dong_xe_sel]
                mean_ref = seg.get("mean", stats["mean"].mean())
                std_ref  = seg.get("std", stats["std"].mean())
                seg_min  = seg.get("min", np.nan)
                seg_max  = seg.get("max", np.nan)
                p10      = seg.get("p10", np.nan)
                p90      = seg.get("p90", np.nan)
            else:
                if "Gi√°" in df.columns and not df["Gi√°"].isna().all():
                    mean_ref = df["Gi√°"].mean()
                    std_ref  = df["Gi√°"].std()
                    seg_min  = df["Gi√°"].min()
                    seg_max  = df["Gi√°"].max()
                    p10      = df["Gi√°"].quantile(0.10)
                    p90      = df["Gi√°"].quantile(0.90)
                else:
                    mean_ref = 0.0
                    std_ref  = 1.0
                    seg_min  = np.nan
                    seg_max  = np.nan
                    p10 = p90 = np.nan

            # -------------------------
            # B∆∞·ªõc 3: Residual-z
            # -------------------------
            if pd.isna(std_ref) or std_ref == 0:
                residual_z = np.nan
            else:
                residual_z = (resid - mean_ref) / std_ref

            # -------------------------
            # B∆∞·ªõc 4: Min/Max v√† P10‚ÄìP90 violations
            # -------------------------
            minmax_violation = 1 if (
                (not pd.isna(seg_min) and gia_thuc < seg_min) or 
                (not pd.isna(seg_max) and gia_thuc > seg_max)
            ) else 0

            percentile_violation = 1 if (
                (not pd.isna(p10) and gia_thuc < p10) or 
                (not pd.isna(p90) and gia_thuc > p90)
            ) else 0

            # -------------------------
            # B∆∞·ªõc 5: T√≠nh ƒëi·ªÉm b·∫•t th∆∞·ªùng t·ªïng (n·ªôi b·ªô)
            # -------------------------
            w1, w2, w3 = 0.40, 0.40, 0.20
            cap_z = 5.0

            # residual-z score: chu·∫©n ho√° 0‚Äì100 (n·∫øu residual_z l√† NaN -> 0)
            residual_score = min(1.0, abs(residual_z) / cap_z) * 100 if pd.notna(residual_z) else 0.0
            minmax_score = minmax_violation * 100
            p10p90_score = percentile_violation * 100

            anomaly_score = (
                w1 * residual_score +
                w2 * minmax_score +
                w3 * p10p90_score
            )
            anomaly_score = float(np.clip(anomaly_score, 0, 100))

            # -------------------------
            # B∆∞·ªõc 6: PH√ÇN LO·∫†I
            # - N·∫øu vi ph·∫°m min/max ho·∫∑c p10/p90 ‚áí B·∫§T TH∆Ø·ªúNG NGAY (theo h∆∞·ªõng)
            # - Else n·∫øu residual_z c√≥ gi√° tr·ªã v√† |residual_z| >= 2 ‚áí B·∫§T TH∆Ø·ªúNG (theo h∆∞·ªõng)
            # - Else n·∫øu anomaly_score >= 45 ‚áí B·∫§T TH∆Ø·ªúNG (theo h∆∞·ªõng)
            # - Else ‚áí B√åNH TH∆Ø·ªúNG
            # -------------------------
            label = "B√åNH TH∆Ø·ªúNG"

            # 1) ∆∞u ti√™n vi ph·∫°m kho·∫£ng (min/max)
            if minmax_violation:
                if pd.notna(seg_min) and gia_thuc < seg_min:
                    label = "R·∫∫ B·∫§T TH∆Ø·ªúNG"
                elif pd.notna(seg_max) and gia_thuc > seg_max:
                    label = "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG"
                else:
                    label = "B√åNH TH∆Ø·ªúNG"

            # 2) n·∫øu kh√¥ng b·ªã minmax, ki·ªÉm tra ph√¢n v·ªã
            elif percentile_violation:
                if pd.notna(p10) and gia_thuc < p10:
                    label = "R·∫∫ B·∫§T TH∆Ø·ªúNG"
                elif pd.notna(p90) and gia_thuc > p90:
                    label = "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG"
                else:
                    label = "B√åNH TH∆Ø·ªúNG"

            # 3) n·∫øu kh√¥ng c√≥ vi ph·∫°m ph√¢n kh√∫c, d√πng residual_z n·∫øu kh·∫£ d·ª•ng
            elif pd.notna(residual_z) and abs(residual_z) >= 2.0:
                label = "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG" if resid > 0 else "R·∫∫ B·∫§T TH∆Ø·ªúNG"

            # 4) backup: d√πng anomaly_score v·ªõi ng∆∞·ª°ng nh·∫°y h∆°n
            elif anomaly_score >= 45:
                label = "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG" if resid > 0 else "R·∫∫ B·∫§T TH∆Ø·ªúNG"

            else:
                label = "B√åNH TH∆Ø·ªúNG"

            # -------------------------
            # B∆∞·ªõc 7: Hi·ªÉn th·ªã k·∫øt qu·∫£ (ch·ªâ nh√£n)
            # -------------------------
            st.markdown("---")
            if label == "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG":
                st.error("üö® **ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG** ‚Äî m·ª©c gi√° cao h∆°n ƒë√°ng k·ªÉ so v·ªõi m·∫∑t b·∫±ng ph√¢n kh√∫c.")
            elif label == "R·∫∫ B·∫§T TH∆Ø·ªúNG":
                st.error("üö® **R·∫∫ B·∫§T TH∆Ø·ªúNG** ‚Äî m·ª©c gi√° th·∫•p h∆°n ƒë√°ng k·ªÉ so v·ªõi ph√¢n kh√∫c.")
            else:
                st.success("‚úî **B√åNH TH∆Ø·ªúNG** ‚Äî m·ª©c gi√° ph√π h·ª£p so v·ªõi th·ªã tr∆∞·ªùng.")

elif choice == 'Danh s√°ch xe gi√° b·∫•t th∆∞·ªùng': 

    st.write("### Danh s√°ch c√°c xe b·∫•t th∆∞·ªùng trong t·∫≠p d·ªØ li·ªáu")

    # --- 0. N·∫øu df ch∆∞a c√≥ (v√¨ b·∫°n c√≥ th·ªÉ ch·ªâ load df ·ªü branch kh√°c), c·ªë g·∫Øng load t·ª´ file Excel ---
    if 'df' not in globals() and 'df' not in locals():
        try:
            df = pd.read_excel("data_motobikes.xlsx")
            st.info("ƒê√£ load d·ªØ li·ªáu t·ª´ data_motobikes.xlsx")
        except Exception as e:
            st.error(f"Kh√¥ng t√¨m th·∫•y DataFrame 'df' v√† kh√¥ng th·ªÉ load file data_motobikes.xlsx: {e}")
            st.stop()

    # --- 0.5. N·∫øu model ch∆∞a load, c·ªë g·∫Øng load model (c·∫ßn ƒë·ªÉ d·ª± ƒëo√°n) ---
    if 'model' not in globals() and 'model' not in locals():
        try:
            model = joblib.load("motobike_price_model_project_1.pkl")
            st.info("ƒê√£ load model d·ª± ƒëo√°n.")
        except Exception as e:
            st.error(f"Kh√¥ng t√¨m th·∫•y model v√† kh√¥ng th·ªÉ load motobike_price_model_project_1.pkl: {e}")
            st.stop()

    # --- 0.75. N·∫øu stats ch∆∞a load, c·ªë g·∫Øng load file residual stats ---
    if 'stats' not in globals() and 'stats' not in locals():
        try:
            stats = pd.read_csv("residual_stats_by_group.csv", index_col=0)
            st.info("ƒê√£ load residual_stats_by_group.csv")
        except Exception as e:
            st.error(f"Kh√¥ng t√¨m th·∫•y residual_stats_by_group.csv: {e}")
            st.stop()

    # --- 1. Chu·∫©n h√≥a b·∫£n sao c·ªßa df (kh√¥ng s·ª≠a df g·ªëc) ---
    df_local = df.copy()
    # Chuy·ªÉn Gi√° sang s·ªë (lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i s·ªë)
    df_local["Gi√°"] = df_local["Gi√°"].astype(str).str.replace(r"[^\d]", "", regex=True)
    df_local["Gi√°"] = pd.to_numeric(df_local["Gi√°"], errors="coerce")
    # NƒÉm ƒëƒÉng k√Ω -> numeric, t√≠nh Tu·ªïi xe
    df_local["NƒÉm ƒëƒÉng k√Ω"] = pd.to_numeric(df_local["NƒÉm ƒëƒÉng k√Ω"], errors="coerce")
    df_local["Tu·ªïi xe"] = datetime.now().year - df_local["NƒÉm ƒëƒÉng k√Ω"]

    # --- 2. D·ª± ƒëo√°n (vectorized n·∫øu ƒë∆∞·ª£c, fallback v√≤ng l·∫∑p n·∫øu model kh√¥ng ch·∫•p nh·∫≠n DataFrame) ---
    features = [
        'Th∆∞∆°ng hi·ªáu','D√≤ng xe','T√¨nh tr·∫°ng','Lo·∫°i xe',
        'Dung t√≠ch xe','NƒÉm ƒëƒÉng k√Ω','Tu·ªïi xe','Xu·∫•t x·ª©',
        'Ch√≠nh s√°ch b·∫£o h√†nh','S·ªë Km ƒë√£ ƒëi'
    ]

    with st.spinner("ƒêang d·ª± ƒëo√°n cho to√†n b·ªô dataset (m·ªôt l·∫ßn) ..."):
        try:
            X = df_local[features]
            y_hat = model.predict(X)
            y_hat = np.array(y_hat, dtype=float) * 1_000_000   # gi·ªØ logic nh√¢n tri·ªáu n·∫øu model tr·∫£ v·ªÅ tri·ªáu
            df_local["Gi√° d·ª± ƒëo√°n"] = y_hat
        except Exception:
            # fallback t·ª´ng d√≤ng
            predicted = []
            for _, r in df_local.iterrows():
                x = pd.DataFrame([{c: r[c] for c in features}])
                try:
                    y = model.predict(x)[0]
                    predicted.append(float(y) * 1_000_000)
                except Exception:
                    predicted.append(np.nan)
            df_local["Gi√° d·ª± ƒëo√°n"] = predicted

    # --- 3. T√≠nh residual v√† join stats theo 'D√≤ng xe' (ho·∫∑c d√πng index s·∫µn c√≥) ---
    df_local["Residual"] = df_local["Gi√°"] - df_local["Gi√° d·ª± ƒëo√°n"]

    if "D√≤ng xe" in stats.columns:
        stats_idx = stats.set_index("D√≤ng xe")
    else:
        stats_idx = stats

    df_local = df_local.join(stats_idx, on="D√≤ng xe", how="left")

    # T√≠nh z-score (c·∫©n tr·ªçng v·ªõi NaN / std = 0)
    # --- s·ª≠a: x·ª≠ l√Ω std == 0 v√† thay th·∫ø inf ---
    df_local["Residual_z"] = (df_local["Residual"] - df_local["mean"]) / df_local["std"]
    df_local["Residual_z"] = df_local["Residual_z"].replace([np.inf, -np.inf], np.nan)

    # --- 4. T√≠nh c√°c c·ªù vi ph·∫°m v√† ƒëi·ªÉm b·∫•t th∆∞·ªùng t·ªïng ---
    # safe checks: only use columns if they exist after join
    # prepare default zero columns
    df_local["_minmax_violation"] = 0
    df_local["_p10p90_violation"] = 0

    # check existence of stat columns
    has_min = "min" in df_local.columns
    has_max = "max" in df_local.columns
    has_p10 = "p10" in df_local.columns
    has_p90 = "p90" in df_local.columns

    # compute minmax violation safely
    cond_min = pd.Series(False, index=df_local.index)
    cond_max = pd.Series(False, index=df_local.index)
    if has_min:
        cond_min = pd.notna(df_local["min"]) & (df_local["Gi√°"] < df_local["min"])
    if has_max:
        cond_max = pd.notna(df_local["max"]) & (df_local["Gi√°"] > df_local["max"])
    df_local.loc[cond_min | cond_max, "_minmax_violation"] = 1

    # compute percentile violation safely (P10-P90)
    cond_p10 = pd.Series(False, index=df_local.index)
    cond_p90 = pd.Series(False, index=df_local.index)
    if has_p10:
        cond_p10 = pd.notna(df_local["p10"]) & (df_local["Gi√°"] < df_local["p10"])
    if has_p90:
        cond_p90 = pd.notna(df_local["p90"]) & (df_local["Gi√°"] > df_local["p90"])
    df_local.loc[cond_p10 | cond_p90, "_p10p90_violation"] = 1

    # compute Residual_z safely (if mean/std exist)
    # already computed earlier; ensure no inf
    df_local["Residual_z"] = df_local["Residual_z"].replace([np.inf, -np.inf], np.nan)

    # compute residual score scaled to 0-100 using cap_z
    cap_z = 5.0
    df_local["_residual_score"] = df_local["Residual_z"].abs().fillna(0).clip(upper=cap_z) / cap_z * 100
    df_local["_minmax_score"] = df_local["_minmax_violation"] * 100
    df_local["_p10p90_score"] = df_local["_p10p90_violation"] * 100

    # anomaly score with weights w1=0.4, w2=0.4, w3=0.2
    w1, w2, w3 = 0.40, 0.40, 0.20
    df_local["_anomaly_score"] = (
        w1 * df_local["_residual_score"] +
        w2 * df_local["_minmax_score"] +
        w3 * df_local["_p10p90_score"]
    )
    df_local["_anomaly_score"] = df_local["_anomaly_score"].clip(0, 100)

    # --- 5. L·ªçc v√† hi·ªÉn th·ªã k·∫øt qu·∫£ ---
    # ƒëi·ªÅu ki·ªán b·∫•t th∆∞·ªùng:
    #  - ∆∞u ti√™n minmax ho·∫∑c percentile violations
    #  - ho·∫∑c residual_z v∆∞·ª£t ¬±2
    #  - ho·∫∑c anomaly_score >= 60 (backup)
    cond_minmax = df_local["_minmax_violation"] == 1
    cond_percentile = df_local["_p10p90_violation"] == 1
    cond_residualz = df_local["Residual_z"].abs() >= 2
    cond_score = df_local["_anomaly_score"] >= 60

    df_abnormal = df_local[cond_minmax | cond_percentile | cond_residualz | cond_score].copy()

    # th√™m c·ªôt ph√¢n lo·∫°i h∆∞·ªõng (d·ª±a tr√™n residual)
    def decide_label(row):
        # n·∫øu vi ph·∫°m minmax -> ƒë·ªãnh h∆∞·ªõng theo seg min/max
        if row["_minmax_violation"] == 1:
            if pd.notna(row.get("min")) and row["Gi√°"] < row["min"]:
                return "R·∫∫ B·∫§T TH∆Ø·ªúNG"
            if pd.notna(row.get("max")) and row["Gi√°"] > row["max"]:
                return "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG"
        # n·∫øu vi ph·∫°m percentile
        if row["_p10p90_violation"] == 1:
            if pd.notna(row.get("p10")) and row["Gi√°"] < row["p10"]:
                return "R·∫∫ B·∫§T TH∆Ø·ªúNG"
            if pd.notna(row.get("p90")) and row["Gi√°"] > row["p90"]:
                return "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG"
        # else use residual sign
        if pd.notna(row["Residual"]):
            return "ƒê·∫ÆT B·∫§T TH∆Ø·ªúNG" if row["Residual"] > 0 else "R·∫∫ B·∫§T TH∆Ø·ªúNG"
        return "B√åNH TH∆Ø·ªúNG"

    if not df_abnormal.empty:
        df_abnormal["Nh·∫≠n ƒë·ªãnh"] = df_abnormal.apply(decide_label, axis=1)

    if df_abnormal.empty:
        st.success("‚úî Kh√¥ng c√≥ xe b·∫•t th∆∞·ªùng trong dataset.")
    else:
        st.error(f"üí• C√≥ {len(df_abnormal)} xe b·∫•t th∆∞·ªùng:")
        display_cols = [
            "Th∆∞∆°ng hi·ªáu","D√≤ng xe","Lo·∫°i xe",
            "Gi√°","Gi√° d·ª± ƒëo√°n","Residual","Residual_z",
            "_anomaly_score","Nh·∫≠n ƒë·ªãnh"
        ]
        st.dataframe(
            df_abnormal[display_cols].sort_values("_anomaly_score", ascending=False)
        )
        csv_bytes = df_abnormal.to_csv(index=False).encode("utf-8")
        st.download_button("T·∫£i to√†n b·ªô danh s√°ch b·∫•t th∆∞·ªùng (.csv)", csv_bytes, file_name="xe_bat_thuong.csv")